# Laboratorio-7
## Samuel Parra y Miguel Caro
Este repositorio documenta la segunda tarea del curso, centrada en dos grandes componentes: por un lado un sistema de análisis de emociones faciales a partir de la cámara usando MediaPipe, hilos, exclusión mutua y semáforos con interfaz web en Streamlit y empaquetado en Docker, y por otro una exploración teórica de tecnologías de infraestructura y nube (Terraform, Ansible, RabbitMQ, OpenStack y el cuadro de Gartner); a nivel de entorno se asume Ubuntu (en el caso práctico 24.10), con los paquetes básicos instalados mediante `sudo apt update`, `sudo apt install -y software-properties-common`, activación del repositorio `universe` con `sudo add-apt-repository universe` y posterior `sudo apt update`, más la instalación de Python 3, `python3-venv`, `python3-pip`, git y docker con `sudo apt install -y python3 python3-venv python3-pip git docker.io`, comprobando el entorno con `python3 --version`, `pip3 --version` y `docker ps`. La estructura sugerida del repositorio es algo como: una carpeta `Sentimientos_Imagenes` con su `app.py`, `requirements.txt`, `Dockerfile` y archivos auxiliares, y una carpeta `docs/img` con las capturas y diagramas que se refieren más adelante, por ejemplo `sentimientos_streamlit.png`, `sentimientos_diagrama.png` y `tecnologias_mapa.png`, todo documentado en este README junto con un archivo adicional de texto para la parte teórica si se desea. Para aislar dependencias se puede usar un entorno virtual con `python3 -m venv .venv`, activándolo mediante `source .venv/bin/activate`, actualizando `pip` con `pip install --upgrade pip` y desactivándolo al terminar con `deactivate`, aunque en el proyecto de emociones la instalación real de dependencias ocurre dentro de la imagen de Docker (el entorno del host se usa principalmente para edición de código). En el componente de “Sentimientos por imágenes” el objetivo es detectar el estado “feliz”, “enojado” o “triste” a partir del rostro captado por la cámara, usando MediaPipe FaceMesh, dos hilos (uno para captura de video y otro para procesamiento), un `Lock` como mecanismo de exclusión mutua para las variables compartidas y un `Semaphore` para sincronizar la llegada de nuevos frames, presentando el resultado en tiempo real en una aplicación web hecha con Streamlit que se ejecuta dentro de un contenedor Docker basado en `python:3.11-slim` para garantizar compatibilidad con `mediapipe`. Dentro de `Sentimientos_Imagenes` se define un `requirements.txt` con `streamlit`, `opencv-python` y `mediapipe==0.10.11` y un `Dockerfile` que hace `FROM python:3.11-slim`, instala librerías de sistema necesarias para OpenCV (`ffmpeg libsm6 libxext6`), copia `requirements.txt`, ejecuta `pip install --no-cache-dir -r requirements.txt`, copia el resto de archivos a `/app`, expone el puerto 8501 y define como comando de inicio `streamlit run app.py --server.port=8501 --server.address=0.0.0.0`. El archivo `app.py` configura MediaPipe FaceMesh con un solo rostro y detección continua, declara variables globales compartidas (`frame_original`, `frame_procesado`, `sentimiento_actual`, un `Lock` llamado `lock_frame`, un semáforo `sem_nuevo_frame` y una bandera `running`), define una función `clasificar_sentimiento_por_landmarks` que toma los landmarks de boca, cejas, ojos, frente y barbilla, normaliza distancias respecto a la altura de la cara y calcula un “smile_score” (compara la altura del centro de la boca con la de las comisuras para distinguir entre sonrisa y gesto neutro/triste) y una medida de distancia ceja-ojo (cejas más bajas implican gesto de enfado), usando umbrales sencillos para devolver una de las tres etiquetas; otra función `procesar_frame` convierte el frame BGR a RGB, pasa por FaceMesh, dibuja los puntos clave, colorea una banda superior de la imagen en amarillo, rojo o azul según el sentimiento y escribe el texto “Sentimiento: …”; el hilo de captura abre `cv2.VideoCapture(0)`, en un bucle lee frames, entra en la sección crítica con `lock_frame` para actualizar `frame_original` y llama `sem_nuevo_frame.release()` para despertar al hilo de procesamiento, durmiendo unos milisegundos para mantener fluidez; el hilo de procesamiento espera con `sem_nuevo_frame.acquire()`, copia el último frame bajo el `Lock`, llama `procesar_frame`, y actualiza `frame_procesado` y `sentimiento_actual`. En la parte de Streamlit se configura la página con título y descripción, se usa `st.session_state["hilos_iniciados"]` para que los hilos se arranquen una sola vez (no cada recarga), se crean dos columnas, una con un `placeholder` de imagen y otra con un `placeholder` de texto, y se ejecuta un bucle que, si hay `frame_proce]()

![WhatsApp Image 2025-11-21 at 9 13 36 PM(4)](https://github.com/user-attachments/assets/cf76059e-0249-4b5a-9c23-3119b6f48a81)
![WhatsApp Image 2025-11-21 at 9 13 36 PM(3)](https://github.com/user-attachments/assets/97b618fb-04f0-4a36-940d-a46ab4b975ca)
![WhatsApp Image 2025-11-21 at 9 13 36 PM(2)](https://github.com/user-attachments/assets/1033c429-2a57-4b1f-8253-35ab19a1025a)
![WhatsApp Image 2025-11-21 at 9 13 36 PM(1)](https://github.com/user-attachments/assets/cd7605ab-8e28-4db2-920f-e020505d951e)
![WhatsApp Image 2025-11-21 at 9 13 36 PM](https://github.com/user-attachments/assets/81ee1577-2a11-4ef2-979b-f3e7392b36b3)


3.	Exploración de tecnologías: Terraform es una herramienta de infraestructura como código (IaC) de HashiCorp que permite describir recursos de infraestructura (máquinas virtuales, redes, almacenamiento, DNS, balanceadores, etc.) mediante archivos declarativos en HCL (HashiCorp Configuration Language). En lugar de crear recursos manualmente en la consola de AWS, Azure, GCP u OpenStack, se definen archivos de configuración versionables en Git y se gestionan con un ciclo típico de comandos: terraform init (inicializa proveedores y backend), terraform plan (muestra qué cambios se aplicarían) y terraform apply (crea o modifica la infraestructura). Al ser multi-proveedor, el mismo lenguaje sirve para nubes públicas (AWS, Azure, GCP, OCI) y entornos on-prem o privados (OpenStack, VMware), lo que reduce el “lock-in” y facilita despliegues reproducibles y automatizados de entornos de IA, clusters de contenedores, colas de mensajes, bases de datos, etc. Ansible es una plataforma de automatización y gestión de configuración que permite describir el estado deseado de servidores y servicios en archivos YAML llamados “playbooks” y aplicarlo de forma remota sin agentes pesados, normalmente vía SSH y Python. Se utiliza para instalar paquetes, gestionar usuarios, desplegar versiones nuevas de aplicaciones, orquestar workflows complejos (por ejemplo: actualizar varios servicios en orden, reiniciar contenedores, aplicar parches de seguridad) y mantener configuraciones homogéneas en docenas o cientos de nodos. En conjunto con Terraform, una práctica común es: Terraform crea las máquinas y redes; Ansible se encarga de instalar Docker, RabbitMQ, runtimes de IA, dependencias de Python y configurar servicios sobre esas máquinas. RabbitMQ (Rabbit) es un “message broker” de código abierto que implementa principalmente el protocolo AMQP y otros estándares (MQTT, STOMP, etc.) para permitir comunicación asíncrona entre aplicaciones. Su modelo se basa en productores que publican mensajes en “exchanges”, reglas de enrutamiento que los conectan con colas, y consumidores que leen mensajes de esas colas. Esto desacopla servicios (por ejemplo, un módulo de adquisición de datos de un módulo de inferencia IA), permite balancear carga entre múltiples consumidores, tolerar fallas (si un consumidor cae, los mensajes quedan en cola) y construir arquitecturas orientadas a eventos donde cada componente se enfoca en su tarea y se comunica a través de mensajes estructurados. Las tecnologías OpenStack para generar nubes propias se basan en una plataforma open source que actúa como sistema operativo de nube: controla grandes pools de cómputo, almacenamiento y red en un datacenter. A través de un dashboard web y APIs, los administradores pueden crear y gestionar máquinas virtuales (Nova), redes virtuales (Neutron), volúmenes de bloque (Cinder), almacenamiento de objetos (Swift), imágenes de sistema (Glance) e identidad/autenticación (Keystone). La idea es construir una nube privada o pública tipo “IaaS” similar a los grandes proveedores, pero con control local sobre infraestructura y datos. Para una universidad o entidad pública que quiera infraestructura de IA, OpenStack permite ofrecer a grupos de investigación máquinas virtuales, GPUs, redes aisladas y volúmenes, todo gestionado centralmente y automatizable vía Terraform y Ansible. Respecto al cuadro de Gartner orientado a la nube (Magic Quadrant for Strategic Cloud Platform Services, SCPS), evalúa a los grandes proveedores de nube en dos ejes: “Capacidad de ejecución” y “Completitud de visión”. Proveedores como AWS, Microsoft Azure y Google Cloud suelen aparecer en el cuadrante de “Leaders”, lo que refleja su madurez en infraestructura, servicios de plataforma, herramientas de IA/ML gestionadas y ecosistemas de socios. El concepto de SCPS integra servicios de infraestructura (cómputo, red, almacenamiento), servicios de plataforma (bases de datos, analítica, IA, integración) y capacidades de transformación digital. Para un ingeniero electrónico que diseña soluciones de IA, este tipo de análisis sirve para decidir dónde alojar entrenamientos, dónde desplegar APIs de inferencia, qué nube ofrece mejores servicios de datos o de seguridad gestionada y cómo combinar nubes públicas con nubes privadas basadas en OpenStack, manteniendo flexibilidad y soberanía de datos.
	4.	Propuesta para la convocatoria MinCiencias “Colombia Inteligente: Infraestructura para el desarrollo de la IA”: la convocatoria “Colombia Inteligente – Infraestructura para el desarrollo de la inteligencia artificial” busca financiar capacidades e infraestructura que soporten investigación, formación, transferencia tecnológica y despliegue de IA en el país, con énfasis en articulación entre academia, sector público y ecosistema productivo. En este contexto, como ingenieros electrónicos con formación en Sistemas Digitales III, se plantea lo siguiente.

a) Propuesta de proyecto: Título tentativo: “Plataforma distribuida de monitoreo inteligente de infraestructura crítica en ciudades intermedias”. Problema: muchas ciudades intermedias y municipios colombianos carecen de monitoreo continuo sobre infraestructura crítica (alumbrado público, subestaciones eléctricas urbanas pequeñas, gabinetes de telecomunicaciones, estaciones ambientales, estaciones de bombeo), lo que se traduce en fallas no detectadas, pérdidas de energía, baja calidad del servicio y dificultades para planear mantenimiento y expansión. Alineación con la convocatoria: el proyecto propone una infraestructura de IA que combine sensores electrónicos, redes de comunicación, cómputo en el borde (edge) y cómputo en la nube para capturar, procesar y analizar datos de infraestructura crítica, generando alertas tempranas y reportes que apoyen la toma de decisiones de entidades territoriales y empresas de servicios públicos, en línea con el propósito de impulsar la infraestructura para el desarrollo de la IA que plantea MinCiencias. Objetivo general: diseñar e implementar una plataforma distribuida que integre dispositivos electrónicos IoT, un sistema de mensajería basado en colas, microservicios de analítica e IA contenedorizados y una infraestructura híbrida (OpenStack + nube pública) gestionada como código, para la detección temprana de fallas y anomalías en infraestructura crítica urbana. Objetivos específicos: (1) diseñar nodos de adquisición basados en microcontroladores (por ejemplo ESP32) y sensores (corriente, voltaje, vibración, temperatura, humedad, luminancia) para postes, gabinetes y estaciones críticas; (2) implementar un canal de comunicación confiable (por ejemplo MQTT sobre Wi-Fi/4G) hacia un broker de mensajes (RabbitMQ); (3) desarrollar microservicios en Python que consuman datos de las colas, apliquen modelos de detección de anomalías (series de tiempo, clasificación simple) y generen indicadores de riesgo; (4) desplegar la infraestructura sobre una nube privada basada en OpenStack y una nube pública (por ejemplo para entrenamiento de modelos), gestionadas con Terraform (provisión) y Ansible (configuración); (5) implementar un panel web para visualización de indicadores, mapas de calor y gestión de alertas para operadores. Resultados esperados: un piloto en una ciudad intermedia con monitoreo en tiempo real de algunos circuitos de alumbrado, gabinetes eléctricos u otra infraestructura crítica, reducción de tiempos de detección de fallas, generación de datos abiertos para investigación y un repositorio documentado con configuraciones de Terraform/Ansible y contenedores reproducibles.

c) Tecnologías futuras sugeridas como “experto” en Digitales III: desde la perspectiva de sistemas digitales e IA embebida, se sugieren al menos cuatro líneas tecnológicas clave. (1) Aceleradores de IA en el borde (edge AI): uso de módulos como Nvidia Jetson, Google Coral TPU u otros SoC con núcleos de IA para ejecutar inferencia directamente cerca de la fuente de datos, reduciendo latencia y tráfico hacia la nube. En futuros proyectos, la infraestructura de IA del país debería incluir clusters de nodos edge para visión por computador, audio, mantenimiento predictivo y analítica de sensores en tiempo real. (2) Plataformas de contenedores y orquestación: además de Docker, el uso de Kubernetes y derivados ligeros (K3s, MicroK8s, OpenShift) en nubes públicas y privadas, integrados con OpenStack, para gestionar despliegues de microservicios de IA, escalar réplicas de modelos, hacer “rolling updates” y balancear peticiones. (3) Observabilidad y MLOps: incorporar herramientas de observabilidad (Prometheus, Grafana, Loki) y de MLOps (MLflow, Kubeflow, herramientas de monitoreo de modelos) para medir desempeño de modelos de IA en producción, detectar deriva de datos, gestionar versiones y facilitar el reentrenamiento, de manera que la infraestructura de IA no sea solo hardware sino un ciclo de vida completo de modelos y datos. (4) Tecnologías de datos y gobernanza: adoptar soluciones modernas de almacenamiento y lagos de datos (data lakes), catálogos de datos, mecanismos de gobernanza y seguridad (encriptación, control de accesos, anonimización) que permitan compartir datos entre instituciones respetando la normativa y los derechos de los ciudadanos. (5) Integración con normas y políticas nacionales de IA: aprovechar la política pública de IA en Colombia y convocatorias como “Colombia Inteligente” para alinear proyectos de electrónica y sistemas digitales con estándares de ética, transparencia, uso responsable de datos y enfoque territorial, asegurando que la tecnología se adapte a la realidad de municipios con limitaciones de conectividad, recursos y capacidades técnicas.
